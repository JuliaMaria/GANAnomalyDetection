{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from: https://github.com/sintel-dev/Orion/issues/221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_anomalies(filename, signal, edges=False):\n",
    "    anomalies = pd.read_csv(filename)\n",
    "    anomalies = anomalies.set_index('signal').loc[signal].values[0]\n",
    "    anomalies = pd.DataFrame(json.loads(anomalies), columns=['start', 'end'])\n",
    "\n",
    "    if edges:\n",
    "        data = download(signal)\n",
    "        start = data.timestamp.min()\n",
    "        end = data.timestamp.max()\n",
    "\n",
    "        anomalies['score'] = 1\n",
    "        parts = np.concatenate([\n",
    "            [[start, anomalies.start.min(), 0]],\n",
    "            anomalies.values,\n",
    "            [[anomalies.end.max(), end, 0]]\n",
    "        ], axis=0)\n",
    "        anomalies = pd.DataFrame(parts, columns=['start', 'end', 'score'])\n",
    "\n",
    "    return anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orion import Orion\n",
    "from orion.primitives.tadgan import TadGAN\n",
    "from orion.evaluation.contextual import contextual_confusion_matrix\n",
    "import orion.data as od\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "SIGNALS_SMAP = (\n",
    "'P-1', 'S-1', 'E-1', 'E-2', 'E-3', 'E-4', 'E-5', 'E-6', 'E-7',\n",
    "\t'E-8', 'E-9', 'E-10', 'E-11', 'E-12', 'E-13', 'A-1', 'D-1', 'P-3',\n",
    "\t'D-2', 'D-3', 'D-4', 'A-2', 'A-3', 'A-4', 'G-1', 'G-2', 'D-5',\n",
    "\t'D-6', 'D-7', 'F-1', 'P-4', 'G-3', 'T-1', 'T-2', 'D-8', 'D-9',\n",
    "\t'F-2', 'G-4', 'T-3', 'D-11', 'D-12', 'B-1', 'G-6', 'G-7', 'P-7',\n",
    "\t'R-1', 'A-5', 'A-6', 'A-7', 'D-13', 'A-8', 'A-9', 'F-3'\n",
    ")\n",
    "\n",
    "SIGNALS_SML = (\n",
    "'M-6', 'M-1', 'M-2', 'S-2', 'P-10', 'T-4', 'T-5', 'F-7', 'M-3', 'M-4' \n",
    "\t'M-5', 'P-15', 'C-1', 'C-2', 'T-12', 'T-13', 'F-4', 'F-5', 'D-14', \n",
    "\t'T-9', 'P-14', 'T-8', 'P-11', 'D-15', 'D-16', 'M-7', 'F-8'\n",
    ")\n",
    "\n",
    "DATAPATH = 'csv/'\n",
    "\n",
    "\n",
    "with open('tadgan_msl.json') as f:\n",
    "\thyperparameters = json.load(f)\n",
    "\n",
    "results = np.zeros([len(SIGNALS_SML), 4]) #[tn, fp, fn, tp]\n",
    "for i, signal in tqdm(enumerate(SIGNALS_SML)):\n",
    "\n",
    "\torion = Orion(pipeline = 'tadgan.json', hyperparameters = hyperparameters['init_params'])\n",
    "\t\n",
    "\ttrain_data = pd.read_csv(DATAPATH + signal +'-train.csv')\n",
    "\ttest_data = pd.read_csv(DATAPATH + signal +'-test.csv')\n",
    "\ttrue_anomalies = load_anomalies('labels.csv', signal)\n",
    "\torion.fit(train_data)\n",
    "\n",
    "\tanomalies = orion.detect(test_data)\n",
    "\t\t\n",
    "\tresults[i, :] = contextual_confusion_matrix(true_anomalies, anomalies, weighted=False)\n",
    "\t\n",
    "\tnp.save('confusion_matrix.npy', results)\n",
    "\t\t\t\n",
    "print(\"f1 score is\" + str(np.sum(results[:, 3])/(np.sum(results[:, 3]) + .5*(np.sum(results[:, 1]) + np.sum(results[:, 2])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
